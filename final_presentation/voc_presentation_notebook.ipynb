{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FileUtil Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.file_util import FileUtil\n",
    "\n",
    "file_util = FileUtil()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Raw Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = file_util.get_raw_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.transformations import apply_cleaning_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = apply_cleaning_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sentiment_analysis.train.train import sentiment_analysis_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.topic_modelling.train.train import topic_modelling_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling_train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = file_util.get_metrics(\"sentiment_analysis\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_prauc = sorted(list(map(lambda item: (item[0], item[1][\"PR AUC\"]), metrics.items())), key = lambda x: x[1])\n",
    "print(\"Best model is {} with PR-AUC {}\".format(models_prauc[-1][0], models_prauc[-1][1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = file_util.get_topics_html(\"LDA\")\n",
    "fig.update_layout(width = 700, height = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = file_util.get_topics_html(\"BERTopic\")\n",
    "fig.update_layout(width = 700, height = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = file_util.get_topics_html(\"NMF\")\n",
    "fig.update_layout(width = 700, height = 550)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict reviews_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.predict import predict_sentiment_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_util.best_sentiment_analysis_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_util.TEST_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert = predict_sentiment_topic()\n",
    "test_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert.drop([\"cleaned_text\", \"subtopic\", \"topic\"], axis = 1, inplace = True)\n",
    "test_bert.rename(columns = {\"partially_cleaned_text\": \"Text\", \"date\": \"Time\", \"sentiment\": \"predicted_sentiment\", \n",
    "                            \"sentiment_prob\": \"predicted_sentiment_prob\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bert.to_csv(\"final_presentation/reviews_test_predictions_h2o2.ai.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra (Prediction with Other Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_util.best_sentiment_analysis_model = \"Logistic Regression\"\n",
    "test_logreg = predict_sentiment_topic()\n",
    "test_logreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_util.best_sentiment_analysis_model = \"LSTM\"\n",
    "test_lstm = predict_sentiment_topic()\n",
    "test_lstm.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.visualisation.dashboard_viz import *\n",
    "\n",
    "vis_df = reformat_data(test_bert)\n",
    "pio.renderers.default = \"svg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need Weiqing or Madeline help\n",
    "\n",
    "sentiment_pie_chart_fig = sentiment_pie_chart(vis_df)\n",
    "sentiment_trend_fig = sentiment_line_chart_over_time(vis_df)\n",
    "topics_sentiment_fig = topics_bar_chart(vis_df)\n",
    "\n",
    "display(sentiment_pie_chart_fig.update_layout(width = 500, height = 300, title='Overall Sentiment Breakdown'))\n",
    "display(sentiment_trend_fig.update_layout(title='Sentiment trend'))\n",
    "display(topics_sentiment_fig.update_layout(title='Topics by Sentiment'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_pie_chart_fig = topics_pie_chart(vis_df)\n",
    "topics_bar_chart_fig = topics_bar_chart_over_time(vis_df, time_frame='Q')\n",
    "top_key_words_fig = visualise_all_topics(vis_df)\n",
    "\n",
    "display(topics_pie_chart_fig.update_layout(width = 500, height = 300, title='Frequency of topics'))\n",
    "display(topics_bar_chart_fig.update_layout(title='Topics over Time'))\n",
    "display(top_key_words_fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations for specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtopics in each topic\n",
    "select_topic = 'Drinks'\n",
    "\n",
    "subtopic_fig = get_subtopics(vis_df, topic=select_topic)\n",
    "subtopic_sentiment_fig = sentiment_pie_chart(vis_df[vis_df[\"topic\"]==select_topic])\n",
    "\n",
    "display(subtopic_sentiment_fig.update_layout(width = 500, height = 300,  title=f'Sentiment Breakdown for {select_topic}'))\n",
    "display(subtopic_fig.update_layout(width = 500, height = 300))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clift\\github\\h2o2.ai\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clift\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\clift\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import src.unittest.unit_testing\n",
    "from src.unittest.unit_testing import unit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Methods in unit testing:\", [method for method in dir(src.unittest.unit_testing) if method[:4] == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at c:\\Users\\clift\\github\\h2o2.ai\\src/models/sentiment_analysis\\train\\bert_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at c:\\Users\\clift\\github\\h2o2.ai\\src/models/sentiment_analysis\\train\\bert_model were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at c:\\Users\\clift\\github\\h2o2.ai\\src/models/sentiment_analysis\\train\\bert_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "2023-04-05 14:18:51,043 - Lbl2TransformerVec - INFO - Compute keyword embeddings\n",
      "2023-04-05 14:18:51,422 - Lbl2TransformerVec - INFO - Compute document embeddings\n",
      "2023-04-05 14:19:07,895 - Lbl2TransformerVec - INFO - Train label embeddings\n",
      "2023-04-05 14:19:07,964 - Lbl2TransformerVec - INFO - Get document embeddings from model\n",
      "2023-04-05 14:19:07,965 - Lbl2TransformerVec - INFO - Calculate document<->label similarities\n",
      "2023-04-05 14:19:08,040 - Lbl2TransformerVec - INFO - Compute keyword embeddings\n",
      "2023-04-05 14:19:08,040 - Lbl2TransformerVec - INFO - Compute keyword embeddings\n",
      "2023-04-05 14:19:08,343 - Lbl2TransformerVec - INFO - Compute document embeddings\n",
      "2023-04-05 14:19:08,343 - Lbl2TransformerVec - INFO - Compute document embeddings\n",
      "2023-04-05 14:19:24,875 - Lbl2TransformerVec - INFO - Train label embeddings\n",
      "2023-04-05 14:19:24,875 - Lbl2TransformerVec - INFO - Train label embeddings\n",
      "2023-04-05 14:19:24,945 - Lbl2TransformerVec - INFO - Get document embeddings from model\n",
      "2023-04-05 14:19:24,945 - Lbl2TransformerVec - INFO - Get document embeddings from model\n",
      "2023-04-05 14:19:24,946 - Lbl2TransformerVec - INFO - Calculate document<->label similarities\n",
      "2023-04-05 14:19:24,946 - Lbl2TransformerVec - INFO - Calculate document<->label similarities\n",
      "c:\\Users\\clift\\github\\h2o2.ai\\src\\models\\predict.py:23: UserWarning: No entries in dataframe. Returning empty dataframe.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "unit_test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        if os.path.basename(root) == \"__pycache__\":\n",
    "            continue\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files(\"src\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.file_util import FileUtil\n",
    "print(\"Methods in FileUtil:\", [func for func in dir(FileUtil) if callable(getattr(FileUtil, func)) and not func.startswith(\"__\")])\n",
    "print(\"Attributes in FileUtil:\", list(FileUtil().__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sentiment_analysis.train.bert import BERT\n",
    "print(\"Methods in BERT:\", [func for func in dir(BERT) if callable(getattr(BERT, func)) and not func.startswith(\"__\")])\n",
    "print(\"Attributes in BERT:\", list(BERT().__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.topic_modelling.train.lda import LDA\n",
    "print(\"Methods in LDA:\", [func for func in dir(LDA) if callable(getattr(LDA, func)) and not func.startswith(\"__\")])\n",
    "print(\"Attributes in LDA:\", list(LDA().__dict__.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.topic_modelling.train.bertopic import BERTopic_Module\n",
    "print(\"Methods in BERTopic_Module:\", [func for func in dir(BERTopic_Module) if callable(getattr(BERTopic_Module, func)) and not func.startswith(\"__\")])\n",
    "print(\"Attributes in BERTopic_Module:\", list(BERTopic_Module().__dict__.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docstrings Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(FileUtil.put_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_sentiment_topic.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sentiment_analysis_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(topic_modelling_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
